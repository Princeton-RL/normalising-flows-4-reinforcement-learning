# Normalizing Flows are Capable Models for RL

## üìÑ Paper

- **[Normalizing Flows are Capable Models for RL](https://arxiv.org/abs/2505.23527)**  
  *Raj Ghugare, Benjamin Eysenbach*

## üåê Project Page
- **[Project Website](https://rajghugare19.github.io/nf4rl/index.html)**  
  Includes abstract and results.

# Installation and usage
Separate instructions for each RL task can be found in the respective subfolders.

- [Imitation learning and conditional imitation learning](https://github.com/Princeton-RL/normalising-flows-4-reinforcement-learning/tree/main/il-and-cil)
- [Offline RL](https://github.com/Princeton-RL/normalising-flows-4-reinforcement-learning/tree/main/offline-rl)
- [Unsupervised goal conditional RL](https://github.com/Princeton-RL/normalising-flows-4-reinforcement-learning/tree/main/unsupservised-gcrl)

# Acknowledgments

We thank the respective authors for their awesome contributions.

- [real-nvp-pytorch](https://github.com/senya-ashukha/real-nvp-pytorch) for a simple RealNVP implementation.
- [ogbench](https://github.com/seohongpark/ogbench/tree/master) for offline GCRL benchmarks and baseline code.
- [fql](https://github.com/seohongpark/fql) for offline RL benchmarks and baseline code.
- [tarflow](https://github.com/apple/ml-tarflow) for a neat normalizing flow codebase.
